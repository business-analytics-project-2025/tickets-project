{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479025d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports & Settings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "seed        = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Hyperparameters\n",
    "data_path   = \"Cleaned_Tickets.csv\"\n",
    "pretrained  = \"microsoft/deberta-v3-large\"\n",
    "batch_size  = 16\n",
    "max_length  = 256\n",
    "lr          = 2e-5\n",
    "num_epochs  = 10\n",
    "patience    = 2\n",
    "device      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Threshold grid for tuning\n",
    "threshold_grid = np.linspace(0.1, 0.9, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97721a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load & Prepare Data\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ce3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subject + body\n",
    "df[\"text\"] = df[\"subject\"].str.strip() + \" \" + df[\"body\"].str.strip()\n",
    "\n",
    "# Build list of tags\n",
    "df[\"tags_list\"] = df[[\"tag_1\", \"tag_2\", \"tag_3\"]].values.tolist()\n",
    "all_tags       = sorted({t for tags in df[\"tags_list\"] for t in tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333f4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize tags\n",
    "mlb = MultiLabelBinarizer(classes=all_tags)\n",
    "y = mlb.fit_transform(df[\"tags_list\"])    # shape = [N, num_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d96f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Val / Test split\n",
    "texts    = df[\"text\"].tolist()\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    df[\"text\"].tolist(), y,\n",
    "    test_size=0.10, random_state=seed, shuffle=True\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.10, random_state=seed, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f813e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chria\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# %% Tokenizer & Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/deberta-v3-large\",\n",
    "    use_fast=False,\n",
    "    do_lower_case=True   # if you want all lowercase inputs\n",
    ")\n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts       = texts\n",
    "        self.labels      = labels\n",
    "        self.tokenizer   = tokenizer\n",
    "        self.max_length  = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "train_ds = MultiLabelDataset(X_train, y_train, tokenizer, max_length)\n",
    "val_ds   = MultiLabelDataset(X_val,   y_val,   tokenizer, max_length)\n",
    "test_ds  = MultiLabelDataset(X_test,  y_test,  tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97e28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# %% Model, Loss, Optimizer, Scheduler\n",
    "config    = AutoConfig.from_pretrained(\n",
    "    pretrained,\n",
    "    num_labels=len(all_tags),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model     = AutoModelForSequenceClassification.from_pretrained( pretrained, config=config, weights_only=True)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler   = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf5ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=patience, mode=\"max\", delta=0.0):\n",
    "        self.patience   = patience\n",
    "        self.mode       = mode\n",
    "        self.delta      = delta\n",
    "        self.best       = None\n",
    "        self.counter    = 0\n",
    "        self.should_stop= False\n",
    "\n",
    "    def step(self, metric):\n",
    "        improved = (\n",
    "            metric > self.best + self.delta\n",
    "            if self.mode == \"max\"\n",
    "            else metric < self.best - self.delta\n",
    "        ) if self.best is not None else True\n",
    "\n",
    "        if improved:\n",
    "            self.best    = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d6e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training & Evaluation Functions\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids      = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels         = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits  = outputs.logits\n",
    "        loss    = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def eval_model(loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_logits, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids      = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels         = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits  = outputs.logits\n",
    "            loss    = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_logits .append(logits.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    logits   = np.vstack(all_logits)   # [N, num_tags]\n",
    "    y_true   = np.vstack(all_labels)\n",
    "    probs    = 1 / (1 + np.exp(-logits))\n",
    "    y_pred   = (probs > threshold).astype(int)\n",
    "\n",
    "    prec = precision_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    rec  = recall_score   (y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    f1   = f1_score       (y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    return avg_loss, prec, rec, f1, logits, y_true\n",
    "\n",
    "def tune_thresholds(val_logits, val_true):\n",
    "    best_thresh = []\n",
    "    for i in range(val_true.shape[1]):\n",
    "        best_f1, best_t = 0, 0.5\n",
    "        for t in threshold_grid:\n",
    "            preds_i = (1/(1+np.exp(-val_logits[:,i])) > t).astype(int)\n",
    "            f1_i    = f1_score(val_true[:,i], preds_i, zero_division=0)\n",
    "            if f1_i > best_f1:\n",
    "                best_f1, best_t = f1_i, t\n",
    "        best_thresh.append(best_t)\n",
    "    return np.array(best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "292c5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping()\n",
    "best_f1       = -float(\"inf\")\n",
    "checkpoint    = \"pretrained_tags_model_weights.pt\"\n",
    "\n",
    "train_losses, val_losses, val_f1s = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501fe2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs+\u001b[32m1\u001b[39m):\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m→ Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     tr_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     train_losses.append(tr_loss)\n\u001b[32m     13\u001b[39m     val_loss, val_prec, val_rec, val_f1, _, _ = eval_model(val_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m attention_mask = batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m      9\u001b[39m labels         = batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m logits  = outputs.logits\n\u001b[32m     13\u001b[39m loss    = criterion(logits, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1079\u001b[39m, in \u001b[36mDebertaV2ForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1071\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1075\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1076\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1077\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1090\u001b[39m encoder_layer = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1091\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(encoder_layer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:786\u001b[39m, in \u001b[36mDebertaV2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    776\u001b[39m     token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m    778\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    779\u001b[39m     input_ids=input_ids,\n\u001b[32m    780\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m    784\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    793\u001b[39m encoded_layers = encoder_outputs[\u001b[32m1\u001b[39m]\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.z_steps > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:659\u001b[39m, in \u001b[36mDebertaV2Encoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[39m\n\u001b[32m    657\u001b[39m rel_embeddings = \u001b[38;5;28mself\u001b[39m.get_rel_embedding()\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer):\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     output_states, attn_weights = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    669\u001b[39m         all_attentions = all_attentions + (attn_weights,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:438\u001b[39m, in \u001b[36mDebertaV2Layer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    430\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    431\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m     output_attentions: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    437\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     attention_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m    447\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:371\u001b[39m, in \u001b[36mDebertaV2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    364\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    369\u001b[39m     rel_embeddings=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    370\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     self_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    380\u001b[39m         query_states = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:267\u001b[39m, in \u001b[36mDisentangledSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# bsz x height x length x dimension\u001b[39;00m\n\u001b[32m    265\u001b[39m attention_probs = nn.functional.softmax(attention_scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m attention_probs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m context_layer = torch.bmm(\n\u001b[32m    269\u001b[39m     attention_probs.view(-\u001b[32m1\u001b[39m, attention_probs.size(-\u001b[32m2\u001b[39m), attention_probs.size(-\u001b[32m1\u001b[39m)), value_layer\n\u001b[32m    270\u001b[39m )\n\u001b[32m    271\u001b[39m context_layer = (\n\u001b[32m    272\u001b[39m     context_layer.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, context_layer.size(-\u001b[32m2\u001b[39m), context_layer.size(-\u001b[32m1\u001b[39m))\n\u001b[32m    273\u001b[39m     .permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m    274\u001b[39m     .contiguous()\n\u001b[32m    275\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chria\\Documents\\Μεταπτυχιακό\\Deep Learning\\tickets-project\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% Main Training Loop\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(f\"\\n→ Epoch {epoch}\", flush=True)\n",
    "    tr_loss = train_epoch()\n",
    "    train_losses.append(tr_loss)\n",
    "\n",
    "    val_loss, val_prec, val_rec, val_f1, _, _ = eval_model(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), checkpoint)\n",
    "        print(f\"  New best Val F1={best_f1:.4f} → checkpoint saved.\")\n",
    "\n",
    "    print(\n",
    "        f\"  Train Loss: {tr_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Val F1: {val_f1:.4f} | \"\n",
    "        f\"P: {val_prec:.4f} | R: {val_rec:.4f}\"\n",
    "    )\n",
    "\n",
    "    early_stopper.step(val_f1)\n",
    "    if early_stopper.should_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52afb1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Loss & Val-F1\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, len(val_losses)+1),   val_losses,   label=\"Val   Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
    "\n",
    "plt.plot(range(1, len(val_f1s)+1), val_f1s, label=\"Val micro-F1\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"micro-F1\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c98aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-tag thresholds: [0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.75 0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.8  0.5  0.5  0.5  0.1  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.25 0.5  0.5  0.3  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.2  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.4  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.15 0.25 0.5\n",
      " 0.5  0.15 0.5  0.5  0.5  0.5  0.5  0.5  0.25 0.5  0.5  0.5  0.25 0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.15 0.5  0.5  0.5  0.5  0.4  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.2  0.5  0.4  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.2  0.5  0.5  0.5  0.5  0.1  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.15 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.25 0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.4  0.75 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.1  0.5  0.5  0.5  0.15 0.5  0.8  0.5  0.5  0.5  0.15 0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.25 0.5  0.5  0.35 0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.2  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.1  0.8  0.5\n",
      " 0.5  0.5  0.3  0.3  0.5  0.5  0.15 0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.7  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.25 0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.65 0.5  0.65 0.5  0.5  0.5  0.5\n",
      " 0.5  0.25 0.5  0.5  0.5  0.5  0.5  0.25 0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.3  0.5  0.5  0.1  0.5  0.5  0.5  0.5  0.1\n",
      " 0.5  0.5  0.5  0.5  0.5  0.1  0.5  0.5  0.7  0.5  0.4  0.45 0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.25 0.5  0.1  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.35 0.2  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.15 0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.1  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.6  0.5  0.2  0.5  0.5\n",
      " 0.5  0.5  0.5 ]\n"
     ]
    }
   ],
   "source": [
    "# Threshold tuning on validation set\n",
    "model.load_state_dict(torch.load(checkpoint, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "val_logits_list, val_true_list = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        out = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device)\n",
    "        ).logits.cpu().numpy()\n",
    "        val_logits_list.append(out)\n",
    "        val_true_list .append(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "val_logits = np.vstack(val_logits_list)\n",
    "val_true   = np.vstack(val_true_list)\n",
    "\n",
    "best_thresh = tune_thresholds(val_logits, val_true)\n",
    "print(\"Per-tag thresholds:\", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88ff9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results with tuned thresholds ---\n",
      "Precision: 0.7472\n",
      "Recall   : 0.7655\n",
      "Micro F1 : 0.7562\n",
      "Macro F1 : 0.0860\n",
      "\n",
      "Per-tag performance:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                       AI       0.00      0.00      0.00         0\n",
      "                      API       0.00      0.00      0.00         0\n",
      "          API Integration       0.00      0.00      0.00         0\n",
      "                      AWS       0.00      0.00      0.00         0\n",
      "                   Access       0.00      0.00      0.00         1\n",
      "           Access Control       0.00      0.00      0.00         0\n",
      "        Access Management       0.00      0.00      0.00         1\n",
      "            Accessibility       0.00      0.00      0.00         0\n",
      "                  Account       0.95      0.59      0.73        32\n",
      "                 Accuracy       0.00      0.00      0.00         1\n",
      "           ActiveCampaign       0.00      0.00      0.00         1\n",
      "               Adjustment       0.00      0.00      0.00         0\n",
      "                    Admin       0.00      0.00      0.00         0\n",
      "              Advertising       0.00      0.00      0.00         0\n",
      "                   Agency       0.00      0.00      0.00         0\n",
      "                    Agile       0.00      0.00      0.00         0\n",
      "                    Alert       0.67      0.12      0.21        16\n",
      "                Algorithm       0.00      0.00      0.00         0\n",
      "         Algorithm Update       0.00      0.00      0.00         0\n",
      "                 Analysis       0.00      0.00      0.00         0\n",
      "                Analytics       0.35      0.60      0.44        10\n",
      "        Application Issue       0.00      0.00      0.00         0\n",
      "               Assistance       0.00      0.00      0.00         2\n",
      "                   Attack       0.00      0.00      0.00         0\n",
      "                 Audience       0.00      0.00      0.00         0\n",
      "                    Audio       0.00      0.00      0.00         0\n",
      "           Authentication       0.00      0.00      0.00         0\n",
      "            Authorization       0.00      0.00      0.00         0\n",
      "               Automation       0.00      0.00      0.00         0\n",
      "                   Backup       0.00      0.00      0.00         1\n",
      "            Best Practice       0.00      0.00      0.00         0\n",
      "                  Billing       0.94      1.00      0.97        84\n",
      "                    Brand       0.00      0.00      0.00         1\n",
      "          Brand Awareness       0.00      0.00      0.00         0\n",
      "        Brand Development       0.00      0.00      0.00         1\n",
      "         Brand Engagement       0.00      0.00      0.00         0\n",
      "        Brand Enhancement       0.00      0.00      0.00         0\n",
      "          Brand Expansion       0.00      0.00      0.00         1\n",
      "             Brand Growth       0.00      0.00      0.00         0\n",
      "         Brand Management       0.00      0.00      0.00         0\n",
      "         Brand Visibility       0.00      0.00      0.00         0\n",
      "                 Branding       0.00      0.00      0.00         2\n",
      "                   Breach       0.00      0.00      0.00         2\n",
      "                   Budget       0.00      0.00      0.00         0\n",
      "                      Bug       0.80      0.87      0.83       400\n",
      "                 Business       0.00      0.00      0.00         1\n",
      "     Business Development       0.00      0.00      0.00         0\n",
      "       Business Expansion       0.00      0.00      0.00         0\n",
      "          Business Growth       0.00      0.00      0.00         0\n",
      "     Business Information       0.00      0.00      0.00         0\n",
      "        Business Strategy       0.00      0.00      0.00         0\n",
      "                      CRM       0.00      0.00      0.00         2\n",
      "                    Cache       0.00      0.00      0.00         0\n",
      "                 Campaign       0.40      0.22      0.29         9\n",
      "   Campaign Effectiveness       0.00      0.00      0.00         0\n",
      "      Campaign Management       0.00      0.00      0.00         0\n",
      "     Campaign Performance       0.00      0.00      0.00         0\n",
      "                Campaigns       0.00      0.00      0.00         0\n",
      "                    Cloud       0.00      0.00      0.00         1\n",
      "             Cloud Native       0.00      0.00      0.00         0\n",
      "           Cloud Platform       0.00      0.00      0.00         0\n",
      "           Cloud Software       0.00      0.00      0.00         0\n",
      "             Cloud-Native       0.00      0.00      0.00         1\n",
      "            Collaboration       0.00      0.00      0.00         1\n",
      "            Communication       0.00      0.00      0.00         1\n",
      "                Community       0.00      0.00      0.00         0\n",
      "            Compatibility       0.00      0.00      0.00         6\n",
      "               Compliance       0.69      0.81      0.75        27\n",
      "          Confidentiality       0.29      0.67      0.40         3\n",
      "            Configuration       0.00      0.00      0.00         0\n",
      "                 Conflict       0.00      0.00      0.00         1\n",
      "             Connectivity       0.00      0.00      0.00         2\n",
      "             Consultation       0.00      0.00      0.00         0\n",
      "               Consulting       0.00      0.00      0.00         0\n",
      "                  Content       0.00      0.00      0.00         1\n",
      "         Content Strategy       0.00      0.00      0.00         1\n",
      "             Coordination       0.00      0.00      0.00         1\n",
      "                     Cost       0.00      0.00      0.00         0\n",
      "                    Crash       0.96      0.91      0.93        77\n",
      "                 Customer       0.00      0.00      0.00         1\n",
      "      Customer Engagement       0.00      0.00      0.00         0\n",
      "         Customer Service       0.00      0.00      0.00         1\n",
      "         Customer Support       0.11      0.11      0.11         9\n",
      "            Customization       0.00      0.00      0.00         0\n",
      "             Cyber Attack       0.00      0.00      0.00         0\n",
      "             Cyber Threat       0.00      0.00      0.00         0\n",
      "              Cyberattack       0.00      0.00      0.00         1\n",
      "            Cybersecurity       0.00      0.00      0.00         1\n",
      "                Dashboard       0.00      0.00      0.00         0\n",
      "                     Data       0.25      0.22      0.24         9\n",
      "              Data Access       0.00      0.00      0.00         1\n",
      "            Data Accuracy       0.00      0.00      0.00         0\n",
      "            Data Analysis       0.00      0.00      0.00         0\n",
      "           Data Analytics       0.00      0.00      0.00         3\n",
      "              Data Breach       0.83      0.62      0.71         8\n",
      "         Data Discrepancy       0.00      0.00      0.00         1\n",
      "          Data Encryption       0.00      0.00      0.00         0\n",
      "            Data Exposure       0.00      0.00      0.00         0\n",
      "       Data Inconsistency       0.00      0.00      0.00         0\n",
      "         Data Integration       0.00      0.00      0.00         1\n",
      "           Data Integrity       0.00      0.00      0.00         0\n",
      "               Data Issue       0.00      0.00      0.00         1\n",
      "             Data Leakage       0.00      0.00      0.00         0\n",
      "          Data Management       0.00      0.00      0.00         0\n",
      "             Data Privacy       0.13      0.33      0.19         6\n",
      "          Data Processing       0.00      0.00      0.00         1\n",
      "          Data Protection       0.46      0.40      0.43        15\n",
      "             Data Quality       0.00      0.00      0.00         0\n",
      "            Data Security       0.00      0.00      0.00         1\n",
      "     Data Synchronization       0.00      0.00      0.00         0\n",
      "               Data Tools       0.00      0.00      0.00         0\n",
      "              Data breach       0.00      0.00      0.00         0\n",
      "           DataProtection       0.00      0.00      0.00         0\n",
      "                 Database       0.00      0.00      0.00         1\n",
      "          Decision Making       0.00      0.00      0.00         0\n",
      "                 Delivery       0.00      0.00      0.00         0\n",
      "               Deployment       0.00      0.00      0.00         0\n",
      "                   DevOps       0.00      0.00      0.00         0\n",
      "              Development       0.00      0.00      0.00         0\n",
      "                   Device       0.00      0.00      0.00         0\n",
      "                  Digital       0.00      0.00      0.00         2\n",
      "      Digital Advertising       0.00      0.00      0.00         0\n",
      "         Digital Branding       0.00      0.00      0.00         0\n",
      "         Digital Campaign       0.00      0.00      0.00         0\n",
      "        Digital Campaigns       0.00      0.00      0.00         1\n",
      "         Digital Channels       0.00      0.00      0.00         0\n",
      "        Digital Expansion       0.00      0.00      0.00         1\n",
      "        Digital Marketing       0.00      0.00      0.00         2\n",
      "         Digital Platform       0.00      0.00      0.00         0\n",
      "        Digital Resources       0.00      0.00      0.00         0\n",
      "         Digital Strategy       0.50      0.40      0.44         5\n",
      "          Digital Tactics       0.00      0.00      0.00         0\n",
      "            Digital Tools       0.00      0.00      0.00         0\n",
      "   Digital Transformation       0.00      0.00      0.00         0\n",
      "                 Discount       0.00      0.00      0.00         1\n",
      "              Discrepancy       0.00      0.00      0.00         2\n",
      "                  Display       0.00      0.00      0.00         0\n",
      "                  Dispute       0.00      0.00      0.00         1\n",
      "               Disruption       0.76      0.76      0.76       266\n",
      "                   Docker       0.00      0.00      0.00         0\n",
      "                 Document       0.00      0.00      0.00         0\n",
      "             Documentatio       0.00      0.00      0.00         0\n",
      "            Documentation       0.66      0.82      0.73       240\n",
      "            Documentatoin       0.00      0.00      0.00         0\n",
      "                   Driver       0.00      0.00      0.00         0\n",
      "                      ERP       0.00      0.00      0.00         0\n",
      "               Efficiency       0.00      0.00      0.00         2\n",
      "              Electronics       0.00      0.00      0.00         0\n",
      "                    Email       0.00      0.00      0.00         0\n",
      "          Email Marketing       0.00      0.00      0.00         0\n",
      "                 Employee       0.80      0.80      0.80         5\n",
      "               Encryption       0.00      0.00      0.00         3\n",
      "               Engagement       0.00      0.00      0.00         0\n",
      "              Enhancement       0.00      0.00      0.00         0\n",
      "                Equipment       0.00      0.00      0.00         1\n",
      "                    Error       0.00      0.00      0.00         1\n",
      "                 Exchange       0.00      0.00      0.00         0\n",
      "                  Failure       0.00      0.00      0.00         0\n",
      "                  Feature       0.84      0.81      0.82       332\n",
      "                 Feedback       0.90      0.83      0.86       384\n",
      "                  Finance       0.00      0.00      0.00         1\n",
      "                Financial       0.00      0.00      0.00         0\n",
      "    Financial Institution       0.00      0.00      0.00         0\n",
      "                 Firewall       0.00      0.00      0.00         0\n",
      "                 Firmware       0.00      0.00      0.00         0\n",
      "            Functionality       0.00      0.00      0.00         0\n",
      "                      GCP       0.00      0.00      0.00         0\n",
      "                  Gateway       0.00      0.00      0.00         0\n",
      "         Google Nest Wifi       0.00      0.00      0.00         0\n",
      "                   Growth       0.00      0.00      0.00         0\n",
      "                 Guidance       1.00      0.50      0.67         2\n",
      "                    Guide       0.00      0.00      0.00         0\n",
      "               Guidelines       0.00      0.00      0.00         0\n",
      "                    HIPAA       0.00      0.00      0.00         0\n",
      "                       HR       1.00      0.83      0.91         6\n",
      "                   Hadoop       0.00      0.00      0.00         0\n",
      "                 Hardware       0.76      0.59      0.67        66\n",
      "        Hardware Conflict       0.00      0.00      0.00         0\n",
      "                   Health       0.00      0.00      0.00         1\n",
      "                 HealthIT       0.00      0.00      0.00         0\n",
      "               Healthcare       0.31      0.75      0.44        12\n",
      "            Healthcare IT       0.00      0.00      0.00         0\n",
      "                 Hospital       0.00      0.00      0.00         0\n",
      "  Hospital Infrastructure       0.00      0.00      0.00         0\n",
      "        Hospital Networks       0.00      0.00      0.00         1\n",
      "          Hospital System       0.00      0.00      0.00         0\n",
      "         Hospital Systems       0.00      0.00      0.00         0\n",
      "                       IT       0.61      0.77      0.68       481\n",
      "           Implementation       0.00      0.00      0.00         0\n",
      "              Improvement       0.00      0.00      0.00         1\n",
      "                 Incident       0.14      0.08      0.11        12\n",
      "          Industry Trends       0.00      0.00      0.00         0\n",
      "              Information       0.00      0.00      0.00         0\n",
      "           Infrastructure       0.00      0.00      0.00         2\n",
      "                  Inquiry       0.00      0.00      0.00         0\n",
      "             Installation       0.00      0.00      0.00         0\n",
      "              Instruction       0.00      0.00      0.00         0\n",
      "              Integration       0.23      0.41      0.30        22\n",
      "        Integration Error       0.00      0.00      0.00         0\n",
      "        Integration Issue       0.00      0.00      0.00         0\n",
      "                Interface       0.00      0.00      0.00         0\n",
      "            Investigation       0.00      0.00      0.00         0\n",
      "               Investment       0.00      0.00      0.00         2\n",
      "      Investment Analysis       0.00      0.00      0.00         1\n",
      "      Investment Strategy       0.00      0.00      0.00         0\n",
      "                  Invoice       0.00      0.00      0.00         2\n",
      "                      IoT       0.00      0.00      0.00         0\n",
      "                    Issue       0.50      0.29      0.36         7\n",
      "                     Lead       0.46      0.21      0.29        29\n",
      "                  License       0.00      0.00      0.00         0\n",
      "                    Login       0.92      0.71      0.80        17\n",
      "         Machine Learning       0.00      0.00      0.00         1\n",
      "              Maintenance       0.64      0.38      0.47        24\n",
      "                  Malware       0.60      0.75      0.67         4\n",
      "               Management       0.00      0.00      0.00         0\n",
      "             Market Trend       0.00      0.00      0.00         0\n",
      "                Marketing       0.44      0.70      0.54        46\n",
      "     Marketing Automation       0.00      0.00      0.00         0\n",
      "                  Medical       0.00      0.00      0.00         0\n",
      "             Medical Data       0.00      0.00      0.00         1\n",
      "      Medical Information       0.00      0.00      0.00         1\n",
      "          Medical Records       0.00      0.00      0.00         0\n",
      "                   Memory       0.00      0.00      0.00         0\n",
      "             Microservice       0.00      0.00      0.00         0\n",
      "               Monitoring       0.00      0.00      0.00         0\n",
      "                  Network       0.87      0.79      0.83       194\n",
      "             Notification       0.00      0.00      0.00         5\n",
      "               Onboarding       0.00      0.00      0.00         0\n",
      "          Online Security       0.00      0.00      0.00         0\n",
      "        Online Visibility       0.00      0.00      0.00         0\n",
      "             Optimization       0.00      0.00      0.00         1\n",
      "                    Order       0.00      0.00      0.00         1\n",
      "             Organization       0.00      0.00      0.00         0\n",
      " Organizational Structure       0.00      0.00      0.00         0\n",
      "                   Outage       0.76      0.79      0.77       239\n",
      "                 Outdated       0.00      0.00      0.00         0\n",
      "      Outdated Encryption       0.00      0.00      0.00         0\n",
      "      Outdated Procedures       0.00      0.00      0.00         0\n",
      "        Outdated Protocol       0.00      0.00      0.00         0\n",
      "        Outdated Software       0.00      0.00      0.00         0\n",
      "         Outdated Systems       0.00      0.00      0.00         0\n",
      "         Outdated Version       0.00      0.00      0.00         0\n",
      "                  Outlook       0.00      0.00      0.00         0\n",
      "                    Patch       0.00      0.00      0.00         0\n",
      "      Patient Information       0.00      0.00      0.00         0\n",
      "                  Payment       0.93      0.95      0.94        66\n",
      "          Payment Gateway       0.00      0.00      0.00         0\n",
      "              Performance       0.92      0.89      0.90       673\n",
      "                 Phishing       0.00      0.00      0.00         1\n",
      "                 Platform       0.00      0.00      0.00         0\n",
      "                   Plugin       0.00      0.00      0.00         0\n",
      "                Portfolio       0.00      0.00      0.00         0\n",
      "               PostgreSQL       0.00      0.00      0.00         0\n",
      "                  Pricing       0.33      0.33      0.33         3\n",
      "                  Printer       0.00      0.00      0.00         0\n",
      "                  Privacy       0.00      0.00      0.00         2\n",
      "                  Process       0.00      0.00      0.00         0\n",
      "      Process Improvement       0.00      0.00      0.00         0\n",
      "      Process Integration       0.00      0.00      0.00         0\n",
      "                  Product       0.45      0.64      0.53       108\n",
      "             Product Line       0.00      0.00      0.00         0\n",
      "             Productivity       0.00      0.00      0.00         2\n",
      "                  Project       0.00      0.00      0.00         1\n",
      "       Project Management       0.00      0.00      0.00         1\n",
      "                Promotion       0.00      0.00      0.00         2\n",
      "                 Protocol       0.00      0.00      0.00         0\n",
      "                   Python       0.00      0.00      0.00         0\n",
      "                    Query       0.00      0.00      0.00         1\n",
      "       Query Optimization       0.00      0.00      0.00         0\n",
      "                     RAID       0.00      0.00      0.00         0\n",
      "                  Records       0.00      0.00      0.00         0\n",
      "                 Recovery       0.39      0.42      0.41        26\n",
      "                   Refund       0.52      0.72      0.60        18\n",
      "              Reliability       0.00      0.00      0.00         1\n",
      "              Replacement       0.00      0.00      0.00         0\n",
      "                Reporting       0.00      0.00      0.00         1\n",
      "                  Request       0.00      0.00      0.00         1\n",
      "                 Research       0.00      0.00      0.00         0\n",
      "                 Response       0.00      0.00      0.00         0\n",
      "                   Return       1.00      1.00      1.00         1\n",
      "                     Risk       0.00      0.00      0.00         1\n",
      "          Risk Management       0.00      0.00      0.00         0\n",
      "            Ruby on Rails       0.00      0.00      0.00         0\n",
      "                      SAP       0.00      0.00      0.00         0\n",
      "                      SEO       0.00      0.00      0.00         0\n",
      "                     SaaS       0.00      0.00      0.00         6\n",
      "            SaaS Platform       0.00      0.00      0.00         1\n",
      "                     Saas       0.00      0.00      0.00         0\n",
      "                    Sales       0.83      0.80      0.82       128\n",
      "               Salesforce       0.00      0.00      0.00         1\n",
      "              Scalability       0.67      0.57      0.62         7\n",
      "                 Security       0.96      0.96      0.96       334\n",
      "      Security Management       0.00      0.00      0.00         0\n",
      "          Security Update       0.00      0.00      0.00         0\n",
      "                   Server       0.00      0.00      0.00         1\n",
      "          Server Overload       0.00      0.00      0.00         0\n",
      "                  Service       0.00      0.00      0.00         2\n",
      "       Service Disruption       0.00      0.00      0.00         0\n",
      "                 Shipment       0.00      0.00      0.00         0\n",
      "               Smart Home       0.00      0.00      0.00         0\n",
      "             Social Media       0.00      0.00      0.00         2\n",
      "                 Software       0.42      0.48      0.45        27\n",
      "   Software Compatibility       0.00      0.00      0.00         2\n",
      "        Software Conflict       1.00      0.33      0.50         3\n",
      " Software Development Kit       0.00      0.00      0.00         0\n",
      " Software Incompatibility       0.00      0.00      0.00         0\n",
      "     Software Integration       0.00      0.00      0.00         0\n",
      "           Software Issue       0.00      0.00      0.00         0\n",
      "      Software Limitation       0.00      0.00      0.00         0\n",
      "         Software Support       0.00      0.00      0.00         0\n",
      "          Software Update       0.00      0.00      0.00         4\n",
      "Software Version Mismatch       0.00      0.00      0.00         1\n",
      "                Stability       0.00      0.00      0.00         0\n",
      "                 Strategy       0.54      0.44      0.48        16\n",
      "             Subscription       0.67      0.50      0.57         4\n",
      "                  Support       0.55      0.42      0.48        38\n",
      "                     Swap       0.00      0.00      0.00         0\n",
      "          Synchronization       0.00      0.00      0.00         1\n",
      "                   System       0.00      0.00      0.00         1\n",
      "          System Conflict       0.00      0.00      0.00         0\n",
      "        System Congestion       0.00      0.00      0.00         0\n",
      "           System Failure       0.00      0.00      0.00         0\n",
      "       System Integration       0.00      0.00      0.00         1\n",
      "             System Issue       0.00      0.00      0.00         0\n",
      "        System Resilience       0.00      0.00      0.00         1\n",
      "            System Update       0.00      0.00      0.00         0\n",
      "           System Upgrade       0.00      0.00      0.00         0\n",
      "           System details       0.00      0.00      0.00         0\n",
      "          Task Assignment       0.00      0.00      0.00         1\n",
      "                     Team       0.00      0.00      0.00         0\n",
      "                     Tech       0.00      0.00      0.00         0\n",
      "             Tech Support       0.45      0.63      0.53       169\n",
      "     Technical Difficulty       0.00      0.00      0.00         0\n",
      "          Technical Issue       0.00      0.00      0.00         0\n",
      "    Technical Malfunction       0.00      0.00      0.00         0\n",
      "        Technical Support       0.00      0.00      0.00         4\n",
      "               Technology       0.00      0.00      0.00         0\n",
      "                   Threat       0.00      0.00      0.00         0\n",
      "                   Ticket       0.00      0.00      0.00         0\n",
      "              Touchscreen       0.00      0.00      0.00         0\n",
      "                 Training       0.67      0.40      0.50         5\n",
      "              Transaction       0.00      0.00      0.00         0\n",
      "          Troubleshooting       0.00      0.00      0.00         1\n",
      "                 Tutorial       0.00      0.00      0.00         0\n",
      "                       UI       0.00      0.00      0.00         0\n",
      "                    UI/UX       0.00      0.00      0.00         0\n",
      "                      USB       0.00      0.00      0.00         0\n",
      "      Unauthorized Access       0.00      0.00      0.00         1\n",
      "                   Update       0.00      0.00      0.00         0\n",
      "                  Upgrade       0.00      0.00      0.00         0\n",
      "                  Urgency       0.00      0.00      0.00         0\n",
      "                   Urgent       0.00      0.00      0.00         1\n",
      "                Usability       0.00      0.00      0.00         1\n",
      "          User Experience       0.00      0.00      0.00         0\n",
      "           User Interface       0.00      0.00      0.00         0\n",
      "                  Utility       0.00      0.00      0.00         0\n",
      "                      VPN       0.00      0.00      0.00         1\n",
      "             Verification       0.00      0.00      0.00         1\n",
      "                Violation       0.00      0.00      0.00         0\n",
      "                    Virus       0.57      0.50      0.53        32\n",
      "            Visualization       0.00      0.00      0.00         0\n",
      "            Vulnerability       1.00      0.14      0.25         7\n",
      "                  Website       0.00      0.00      0.00         0\n",
      "          Website Traffic       0.00      0.00      0.00         0\n",
      "                  Windows       0.00      0.00      0.00         0\n",
      "                 Workflow       0.00      0.00      0.00         3\n",
      "                    macOS       0.00      0.00      0.00         0\n",
      "\n",
      "                micro avg       0.75      0.77      0.76      4900\n",
      "                macro avg       0.09      0.09      0.09      4900\n",
      "             weighted avg       0.75      0.77      0.75      4900\n",
      "              samples avg       0.76      0.77      0.76      4900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Test Evaluation\n",
    "test_loss, test_prec, test_rec, test_f1, _, _ = eval_model(test_loader, threshold=0.0)\n",
    "# we ignore default preds; instead re-compute with tuned thresholds:\n",
    "model.eval()\n",
    "test_logits_list, test_true_list = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        out = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device)\n",
    "        ).logits.cpu().numpy()\n",
    "        test_logits_list.append(out)\n",
    "        test_true_list .append(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "test_logits = np.vstack(test_logits_list)\n",
    "y_true      = np.vstack(test_true_list)\n",
    "probs       = 1 / (1 + np.exp(-test_logits))\n",
    "y_pred      = np.stack([\n",
    "    (probs[:,i] > best_thresh[i]).astype(int)\n",
    "    for i in range(probs.shape[1])\n",
    "], axis=1)\n",
    "\n",
    "micro_f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "macro_f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"\\n--- Test Results with tuned thresholds ---\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, average='micro'):.4f}\")\n",
    "print(f\"Recall   : {recall_score   (y_true, y_pred, average='micro'):.4f}\")\n",
    "print(f\"Micro F1 : {micro_f1:.4f}\")\n",
    "print(f\"Macro F1 : {macro_f1:.4f}\\n\")\n",
    "\n",
    "print(\"Per-tag performance:\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=all_tags,\n",
    "    zero_division=0\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
